import sysimport jsonimport osimport pandas as pdimport numpy as npfrom scipy.stats import kendalltaufrom sklearn.metrics import accuracy_scoretry:    reference_dir = sys.argv[1]    prediction_dirs = sys.argv[2]except:    print('Usage: python3 evaluate.py <reference-dir> <prediction-dir> [--a] [--b] \n\n' \    '<reference-dir>: path to directory containing label_task_a.csv and label_task_b.csv\n' \    '<prediction-dirs>: path to directory containing one or more directories, where each directory contains a prediction_task_a.csv or prediction_task_b.csv\n' \    '--a: if present, evaluate Task A\n' \    '--b: if present, evaluate Task B')task_a_ref_path = os.path.join(reference_dir, 'label_task_a.csv')task_a_ref_df = pd.read_csv(task_a_ref_path)# task_b_ref_path = os.path.join(reference_dir, 'label_task_b.csv')## task_b_ref_df = pd.read_csv(task_b_ref_path)######################### Task A ##################################if '--a' in sys.argv:    submissions_dict = {}    try:        submission_path = os.path.join(prediction_dirs, 'submissions.csv')        submissions_df = pd.read_csv(submission_path)        for i, row in submissions_df.iterrows():            row['Owner'] = 'wangkongqiang'            row['Name'] = 'prediction_task_a'            submissions_dict[row['Name']] = row['Owner']    except FileNotFoundError:        pass    print("submissions_dict:", submissions_dict)    owner_best_dict = {}    ranking = []    for prediction_dir in os.listdir(prediction_dirs):        submission_name = os.path.basename(prediction_dir)        print("submission_name:", submission_name)        prediction_dir = os.path.join(prediction_dirs, submission_name)                if not os.path.isdir(prediction_dir): continue        owner = submissions_dict.get(submission_name, submission_name)        print("owner:",owner)        # Load CSV files        pred_path = os.path.join(prediction_dir, 'prediction_task_a.csv')        try:            pred_df = pd.read_csv(pred_path)        except FileNotFoundError:            try:                jsonl = []                with open(pred_path.replace('csv', 'jsonl')) as f:                    for line in f:                        jsonl.append(json.loads(line))                pred_df = pd.DataFrame(jsonl)                pred_df['label'] = pred_df['predicted_task_a_label']            except:                print(pred_path, 'not found', file=sys.stderr)                continue        # Merge on 'id' to align labels        merged_df = pd.merge(task_a_ref_df, pred_df, on='id', suffixes=('_ref', '_pred'))        # Check for missing predictions        missing_ids = set(task_a_ref_df['id']) - set(pred_df['id'])        if missing_ids:            print(f"Warning: {len(missing_ids)} IDs missing in prediction.")        # Calculate accuracy        accuracy = accuracy_score(merged_df['label_ref'], merged_df['label_pred'])        if owner not in owner_best_dict or accuracy > owner_best_dict[owner][0]:            owner_best_dict[owner] = (accuracy, submission_name)        ranking.append((accuracy, submission_name, owner))    print('\n\n             Task A             \n\n')    print('Rank', 'User', 'Submission', 'Accuracy', 'User\'s best submission?', sep=';')    for i, (acc, name, owner) in enumerate(sorted(ranking, reverse=True)):        print(i+1, owner, name, acc, name==owner_best_dict[owner][1], sep=';')######################### Task B ##################################if '--b' in sys.argv:    submissions_dict = {}    try:        submission_path = os.path.join(prediction_dirs, 'submissions.csv')        submissions_df = pd.read_csv(submission_path)        for i, row in submissions_df.iterrows():            submissions_dict[row['Name']] = row['Owner']    except FileNotFoundError:        pass    owner_best_dict = {}    ranking = []        for prediction_dir in os.listdir(prediction_dirs):        submission_name = os.path.basename(prediction_dir)                prediction_dir = os.path.join(prediction_dirs, submission_name)        if not os.path.isdir(prediction_dir): continue        owner = submissions_dict.get(submission_name, submission_name)        # Load CSVs        pred_path = os.path.join(prediction_dir, 'prediction_task_b.csv')        try:            pred_df = pd.read_csv(pred_path)        except FileNotFoundError:            print(pred_path, 'not found', file=sys.stderr)            continue        # Merge on 'id'        merged_df = pd.merge(task_b_ref_df, pred_df, on='id', suffixes=('_ref', '_pred'))        # Check for missing predictions        missing_ids = set(task_b_ref_df['id']) - set(pred_df['id'])        if missing_ids:            print(f"Warning: {len(missing_ids)} IDs missing in prediction.")        # Extract values        ref = merged_df['label_ref'].to_numpy()        pred = merged_df['label_pred'].to_numpy()        # Compute metric        score_value, _ = kendalltau(pred, ref)                if owner not in owner_best_dict or score_value > owner_best_dict[owner][0]:            owner_best_dict[owner] = (score_value, submission_name)        ranking.append((score_value, submission_name, owner))    print('\n\n             Task B             \n\n')    print('Rank', 'User', 'Submission', 'Kendall\'s Tau', 'User\'s best submission?', sep=';')    for i, (acc, name, owner) in enumerate(sorted(ranking, reverse=True)):        print(i+1, owner, name, acc, name==owner_best_dict[owner][1], sep=';')